{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Feature Class example: using the feature classes to calculate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to use the Radiomics package to directly instantiate the feature classes for feature extraction. \n",
    "Note that this is not the intended standard use. For an example on the standard use with feature extractor, see the `helloRadiomics` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import collections\n",
    "import SimpleITK as sitk\n",
    "import numpy\n",
    "import six\n",
    "import radiomics\n",
    "from radiomics import firstorder, glcm, imageoperations, shape, glrlm, glszm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the test case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the repository is available locally, the test case are also availale (located in pyradiomics/data) and therefore do not need to be downloaded. Otherwise, test cases can be downloaded to temporary files. This is handled by the `radiomics.getTestCase()` function, which checks if the requested test case is available and if not, downloads it. It returns a tuple with the location of the image and mask of the requested test case, or (None, None) if it fails.\n",
    "\n",
    "If the repository is not available locally, `repositoryRoot` will most likely point to an invalid directory, or to a directory which does not contain the test case. In this case, PyRadiomics recognizes this and will revert to downloading test cases or, if already downloaded, the test case in the temporary files.\n",
    "\n",
    "If getting the test case fails, PyRadiomics will log an error explaining the cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repositoryRoot points to the root of the repository. The following line gets that location if this Notebook is run\n",
    "# from it's default location in \\pyradiomics\\examples\\Notebooks\n",
    "repositoryRoot = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "imageName, maskName = radiomics.getTestCase('brain1', repositoryRoot)\n",
    "\n",
    "if imageName is None or maskName is None:  # Something went wrong, in this case PyRadiomics will also log an error\n",
    "    raise Exception('Error getting testcase!')  # Raise exception to prevent cells below from running in case of \"run all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = sitk.ReadImage(imageName)\n",
    "mask = sitk.ReadImage(maskName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {}\n",
    "settings['binWidth'] = 25\n",
    "settings['resampledPixelSpacing'] = None\n",
    "# settings['resampledPixelSpacing'] = [3, 3, 3]  # This is an example for defining resampling (voxels with size 3x3x3mm)\n",
    "settings['interpolator'] = 'sitkBSpline'\n",
    "settings['verbose'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If enabled, resample the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resample if necessary\n",
    "if settings['interpolator'] != None and settings['resampledPixelSpacing'] != None:\n",
    "  image, mask = imageoperations.resampleImage(image, mask, settings['resampledPixelSpacing'], settings['interpolator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculate features using original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crop the image\n",
    "# bb is the bounding box, upon which the image and mask are cropped\n",
    "bb, correctedMask = imageoperations.checkMask(image, mask, label=1)\n",
    "if correctedMask is not None:\n",
    "    mask = correctedMask\n",
    "croppedImage, croppedMask = imageoperations.cropToTumorMask(image, mask, bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Firstorder features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firstOrderFeatures = firstorder.RadiomicsFirstOrder(croppedImage, croppedMask, **settings)\n",
    "\n",
    "# Set the features to be calculated\n",
    "firstOrderFeatures.enableFeatureByName('Mean', True)\n",
    "# firstOrderFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following first order features: \n",
      "Mean\n",
      "\n",
      "    **8. Mean**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{mean} = \\frac{1}{N}\\displaystyle\\sum^{N}_{i=1}{\\textbf{X}(i)}\n",
      "\n",
      "    The average gray level intensity within the ROI.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following first order features: ')\n",
    "for f in firstOrderFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(getattr(firstOrderFeatures, 'get%sFeatureValue' % f).__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating first order features...\n",
      "done\n",
      "Calculated first order features: \n",
      "   Mean : 825.235436307\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating first order features...',)\n",
    "firstOrderFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated first order features: ')\n",
    "for (key, val) in six.iteritems(firstOrderFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Shape Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shapeFeatures = shape.RadiomicsShape(croppedImage, croppedMask, **settings)\n",
    "\n",
    "# Set the features to be calculated\n",
    "# shapeFeatures.enableFeatureByName('Volume', True)\n",
    "shapeFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following shape features: \n",
      "Maximum3DDiameter\n",
      "\n",
      "    **8. Maximum 3D diameter**\n",
      "\n",
      "    Maximum 3D diameter is defined as the largest pairwise Euclidean distance between surface voxels in the ROI.\n",
      "\n",
      "    Also known as Feret Diameter.\n",
      "\n",
      "    .. warning::\n",
      "      This feature is only available when C Extensions are enabled\n",
      "    \n",
      "Compactness2\n",
      "\n",
      "    **6. Compactness 2**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{compactness 2} = 36 \\pi \\frac{V^2}{A^3}\n",
      "\n",
      "    Similar to Sphericity and Compactness 1, Compactness 2 is a measure of how compact the shape of the tumor is\n",
      "    relative to a sphere (most compact). It is a dimensionless measure, independent of scale and orientation. The value\n",
      "    range is :math:`0 < compactness\\ 2 \\leq 1`, where a value of 1 indicates a perfect sphere.\n",
      "\n",
      "    By definition, :math:`compactness\\ 2 = (sphericity)^3`\n",
      "\n",
      "    .. note::\n",
      "      This feature is correlated to Compactness 1, Sphericity and Spherical Disproportion. In the default\n",
      "      parameter file provided in the ``pyradiomics/examples/exampleSettings`` folder, Compactness 1 and Compactness 2\n",
      "      are therefore disabled.\n",
      "    \n",
      "Compactness1\n",
      "\n",
      "    **5. Compactness 1**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{compactness 1} = \\frac{V}{\\sqrt{\\pi A^3}}\n",
      "\n",
      "    Similar to Sphericity, Compactness 1 is a measure of how compact the shape of the tumor is relative to a sphere\n",
      "    (most compact). It is therefore correlated to Sphericity and redundant. It is provided here for completeness.\n",
      "    The value range is :math:`0 < compactness\\ 1 \\leq \\frac{1}{6 \\pi}`, where a value of :math:`\\frac{1}{6 \\pi}`\n",
      "    indicates a perfect sphere.\n",
      "\n",
      "    By definition, :math:`compactness\\ 1 = \\frac{1}{6 \\pi}\\sqrt{compactness\\ 2} =\n",
      "    \\frac{1}{6 \\pi}\\sqrt{sphericity^3}`.\n",
      "\n",
      "    .. note::\n",
      "      This feature is correlated to Compactness 2, Sphericity and Spherical Disproportion. In the default\n",
      "      parameter file provided in the ``pyradiomics/examples/exampleSettings`` folder, Compactness 1 and Compactness 2\n",
      "      are therefore disabled.\n",
      "    \n",
      "Sphericity\n",
      "\n",
      "    **4. Sphericity**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{sphericity} = \\frac{\\sqrt[3]{36 \\pi V^2}}{A}\n",
      "\n",
      "    Sphericity is a measure of the roundness of the shape of the tumor region relative to a sphere. It is a\n",
      "    dimensionless measure, independent of scale and orientation. The value range is :math:`0 < sphericity \\leq 1`, where\n",
      "    a value of 1 indicates a perfect sphere (a sphere has the smallest possible surface area for a given volume,\n",
      "    compared to other solids).\n",
      "\n",
      "    .. note::\n",
      "      This feature is correlated to Compactness 1, Compactness 2 and Spherical Disproportion. In the default\n",
      "      parameter file provided in the ``pyradiomics/examples/exampleSettings`` folder, Compactness 1 and Compactness 2\n",
      "      are therefore disabled.\n",
      "    \n",
      "MinorAxis\n",
      "\n",
      "    **13. Minor Axis**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{minor axis} = 4 \\sqrt{\\lambda_{\\text{minor}}}\n",
      "\n",
      "    \n",
      "Maximum2DDiameterSlice\n",
      "\n",
      "    **9. Maximum 2D diameter (Slice)**\n",
      "\n",
      "    Maximum 2D diameter (Slice) is defined as the largest pairwise Euclidean distance between tumor surface voxels in\n",
      "    the row-column (generally the axial) plane.\n",
      "\n",
      "    .. warning::\n",
      "      This feature is only available when C Extensions are enabled\n",
      "    \n",
      "Elongation\n",
      "\n",
      "    **15. Elongation**\n",
      "\n",
      "    Elongation is calculated using its implementation in SimpleITK, and is defined as:\n",
      "\n",
      "    .. math::\n",
      "      \\textit{elongation} = \\sqrt{\\frac{\\lambda_{\\text{minor}}}{\\lambda_{\\text{major}}}}\n",
      "\n",
      "    Here, :math:`\\lambda_{\\text{major}}` and :math:`\\lambda_{\\text{minor}}` are the lengths of the largest and second\n",
      "    largest principal component axes. The values range between 1 (where the cross section through the first and second\n",
      "    largest principal moments is circle-like (non-elongated)) and 0 (where the object is a single point or 1 dimensional\n",
      "    line).\n",
      "    \n",
      "SurfaceVolumeRatio\n",
      "\n",
      "    **3. Surface Area to Volume ratio**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{surface to volume ratio} = \\frac{A}{V}\n",
      "\n",
      "    Here, a lower value indicates a more compact (sphere-like) shape. This feature is not dimensionless, and is\n",
      "    therefore (partly) dependent on the volume of the ROI.\n",
      "    \n",
      "Volume\n",
      "\n",
      "    **1. Volume**\n",
      "\n",
      "    .. math::\n",
      "      V = \\displaystyle\\sum^{N}_{i=1}{V_i}\n",
      "\n",
      "    The volume of the ROI :math:`V` is approximated by multiplying the number of voxels in the ROI by the volume of a\n",
      "    single voxel :math:`V_i`.\n",
      "\n",
      "    .. note::\n",
      "      In the IBSI feature definitions, a more precise approximation of the volume is used. That method uses tetrahedrons\n",
      "      consisting of the origin and faces in the ROI. Although the method implemented here overestimates the volume,\n",
      "      especially in small volumes, the difference will be negligible in large ROIs.\n",
      "    \n",
      "SphericalDisproportion\n",
      "\n",
      "    **7. Spherical Disproportion**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{spherical disproportion} = \\frac{A}{4\\pi R^2} = \\frac{A}{\\sqrt[3]{36 \\pi V^2}}\n",
      "\n",
      "    Where :math:`R` is the radius of a sphere with the same volume as the tumor, and equal to\n",
      "    :math:`\\sqrt[3]{\\frac{3V}{4\\pi}}`.\n",
      "\n",
      "    Spherical Disproportion is the ratio of the surface area of the tumor region to the surface area of a sphere with\n",
      "    the same volume as the tumor region, and by definition, the inverse of Sphericity. Therefore, the value range is\n",
      "    :math:`spherical\\ disproportion \\geq 1`, with a value of 1 indicating a perfect sphere.\n",
      "\n",
      "    .. note::\n",
      "      This feature is correlated to Compactness 1, Compactness 2 and Sphericity. In the default\n",
      "      parameter file provided in the ``pyradiomics/examples/exampleSettings`` folder, Compactness 1 and Compactness 2\n",
      "      are therefore disabled.\n",
      "    \n",
      "MajorAxis\n",
      "\n",
      "    **12. Major Axis**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{major axis} = 4 \\sqrt{\\lambda_{\\text{major}}}\n",
      "\n",
      "    \n",
      "SurfaceArea\n",
      "\n",
      "    **2. Surface Area**\n",
      "\n",
      "    .. math::\n",
      "      A = \\displaystyle\\sum^{N}_{i=1}{\\frac{1}{2}|\\text{a}_i\\text{b}_i \\times \\text{a}_i\\text{c}_i|}\n",
      "\n",
      "    Where:\n",
      "\n",
      "    :math:`N` is the number of triangles forming the surface mesh of the volume (ROI)\n",
      "\n",
      "    :math:`\\text{a}_i\\text{b}_i` and :math:`\\text{a}_i\\text{c}_i` are the edges of the :math:`i^{\\text{th}}` triangle\n",
      "    formed by points :math:`\\text{a}_i`, :math:`\\text{b}_i` and :math:`\\text{c}_i`\n",
      "\n",
      "    Surface Area is an approximation of the surface of the ROI in mm2, calculated using a marching cubes algorithm.\n",
      "\n",
      "    References:\n",
      "\n",
      "    - Lorensen WE, Cline HE. Marching cubes: A high resolution 3D surface construction algorithm. ACM SIGGRAPH Comput\n",
      "      Graph `Internet <http://portal.acm.org/citation.cfm?doid=37402.37422>`_. 1987;21:163-9.\n",
      "    \n",
      "Flatness\n",
      "\n",
      "    **16. Flatness**\n",
      "\n",
      "    Flatness is calculated using its implementation in SimpleITK, and is defined as:\n",
      "\n",
      "    .. math::\n",
      "      \\textit{flatness} = \\sqrt{\\frac{\\lambda_{\\text{least}}}{\\lambda_{\\text{major}}}}\n",
      "\n",
      "    Here, :math:`\\lambda_{\\text{major}}` and :math:`\\lambda_{\\text{least}}` are the lengths of the largest and smallest\n",
      "    principal component axes. The values range between 1 (non-flat, sphere-like) and 0 (a flat object).\n",
      "    \n",
      "LeastAxis\n",
      "\n",
      "    **14. Least Axis**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{least axis} = 4 \\sqrt{\\lambda_{\\text{least}}}\n",
      "\n",
      "    \n",
      "Maximum2DDiameterColumn\n",
      "\n",
      "    **10. Maximum 2D diameter (Column)**\n",
      "\n",
      "    Maximum 2D diameter (Column) is defined as the largest pairwise Euclidean distance between tumor surface voxels in\n",
      "    the row-slice (usually the coronal) plane.\n",
      "\n",
      "    .. warning::\n",
      "      This feature is only available when C Extensions are enabled\n",
      "    \n",
      "Maximum2DDiameterRow\n",
      "\n",
      "    **11. Maximum 2D diameter (Row)**\n",
      "\n",
      "    Maximum 2D diameter (Row) is defined as the largest pairwise Euclidean distance between tumor surface voxels in the\n",
      "    column-slice (usually the sagittal) plane.\n",
      "\n",
      "    .. warning::\n",
      "      This feature is only available when C Extensions are enabled\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following shape features: ')\n",
    "for f in shapeFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(getattr(shapeFeatures, 'get%sFeatureValue' % f).__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating shape features...\n",
      "done\n",
      "Calculated shape features: \n",
      "   Maximum3DDiameter : 65.5366145873\n",
      "   Compactness2 : 0.114127701901\n",
      "   Maximum2DDiameterSlice : 47.2187913633\n",
      "   Sphericity : 0.485061744222\n",
      "   MinorAxis : 34.8497016669\n",
      "   Compactness1 : 0.0179223276661\n",
      "   Elongation : 0.562117162717\n",
      "   SurfaceVolumeRatio : 0.392308261863\n",
      "   Volume : 16412.6586914\n",
      "   SphericalDisproportion : 2.06159321347\n",
      "   MajorAxis : 61.9972204698\n",
      "   LeastAxis : 28.5844231854\n",
      "   Flatness : 0.461059753466\n",
      "   SurfaceArea : 6438.82160378\n",
      "   Maximum2DDiameterColumn : 44.5487904052\n",
      "   Maximum2DDiameterRow : 61.5801767135\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating shape features...',)\n",
    "shapeFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated shape features: ')\n",
    "for (key, val) in six.iteritems(shapeFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate GLCM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glcmFeatures = glcm.RadiomicsGLCM(croppedImage, croppedMask, **settings)\n",
    "\n",
    "# Set the features to be calculated\n",
    "# glcmFeatures.enableFeatureByName('SumEntropy', True)\n",
    "glcmFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following GLCM features: \n",
      "SumVariance\n",
      "\n",
      "    **26. Sum Variance**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{sum variance} = \\displaystyle\\sum^{2N_g}_{k=2}{(k-SA)^2p_{x+y}(k)}\n",
      "\n",
      "    Sum Variance is a measure of heterogeneity that places higher weights on\n",
      "    neighboring intensity level pairs that deviate more from the mean.\n",
      "    \n",
      "Homogeneity1\n",
      "\n",
      "    **14. Homogeneity 1**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{homogeneity 1} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\frac{p(i,j)}{1+|i-j|}}\n",
      "\n",
      "    Homogeneity 1 is a measure of the similarity in intensity values for\n",
      "    neighboring voxels. It is a measure of local homogeneity that increases\n",
      "    with less contrast in the window.\n",
      "\n",
      "    .. note::\n",
      "      Not present in IBSI feature definitions\n",
      "    \n",
      "Homogeneity2\n",
      "\n",
      "    **15. Homogeneity 2**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{homogeneity 2} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\frac{p(i,j)}{1+|i-j|^2}}\n",
      "\n",
      "    Homogeneity 2 is a measure of the similarity in intensity values\n",
      "    for neighboring voxels.\n",
      "\n",
      "    .. note::\n",
      "      Not present in IBSI feature definitions\n",
      "    \n",
      "ClusterShade\n",
      "\n",
      "    **4. Cluster Shade**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{cluster shade} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}\n",
      "      {\\big(i+j-\\mu_x(i)-\\mu_y(j)\\big)^3p(i,j)}\n",
      "\n",
      "    Cluster Shade is a measure of the skewness and uniformity of the GLCM.\n",
      "    A higher cluster shade implies greater asymmetry about the mean.\n",
      "    \n",
      "MaximumProbability\n",
      "\n",
      "    **23. Maximum Probability**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{maximum probability} = \\max\\big(p(i,j)\\big)\n",
      "\n",
      "    Maximum Probability is occurrences of the most predominant pair of\n",
      "    neighboring intensity values.\n",
      "\n",
      "    .. note::\n",
      "      Defined by IBSI as Joint maximum\n",
      "    \n",
      "Idmn\n",
      "\n",
      "    **19. Inverse Difference Moment Normalized (IDMN)**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{IDMN} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}\n",
      "      { \\frac{p(i,j)}{1+\\left(\\frac{|i-j|^2}{N_g^2}\\right)} }\n",
      "\n",
      "    IDMN (inverse difference moment normalized)  is a measure of the local\n",
      "    homogeneity of an image. IDMN weights are the inverse of the Contrast\n",
      "    weights (decreasing exponentially from the diagonal :math:`i=j` in the GLCM).\n",
      "    Unlike Homogeneity2, IDMN normalizes the square of the difference between\n",
      "    neighboring intensity values by dividing over the square of the total\n",
      "    number of discrete intensity values.\n",
      "    \n",
      "Contrast\n",
      "\n",
      "    **6. Contrast**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{contrast} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{(i-j)^2p(i,j)}\n",
      "\n",
      "    Contrast is a measure of the local intensity variation, favoring values away from the diagonal :math:`(i = j)`. A\n",
      "    larger value correlates with a greater disparity in intensity values among neighboring voxels.\n",
      "    \n",
      "DifferenceEntropy\n",
      "\n",
      "    **9. Difference Entropy**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{difference entropy} = \\displaystyle\\sum^{N_g-1}_{k=0}{p_{x-y}(k)\\log_2\\big(p_{x-y}(k)+\\epsilon\\big)}\n",
      "\n",
      "    Difference Entropy is a measure of the randomness/variability\n",
      "    in neighborhood intensity value differences.\n",
      "    \n",
      "InverseVariance\n",
      "\n",
      "    **22. Inverse Variance**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{inverse variance} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\frac{p(i,j)}{|i-j|^2}},\n",
      "      i \\neq j\n",
      "    \n",
      "Dissimilarity\n",
      "\n",
      "    **11. Dissimilarity**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{dissimilarity} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{|i-j|p(i,j)}\n",
      "\n",
      "    Dissimilarity is a measure of local intensity variation defined as the mean absolute difference between the\n",
      "    neighbouring pairs. A larger value correlates with a greater disparity in intensity values\n",
      "    among neighboring voxels.\n",
      "    \n",
      "SumAverage\n",
      "\n",
      "    **24. Sum Average**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{sum average} = \\displaystyle\\sum^{2N_g}_{k=2}{p_{x+y}(k)k}\n",
      "\n",
      "    Sum Average measures the relationship between occurrences of pairs\n",
      "    with lower intensity values and occurrences of pairs with higher intensity\n",
      "    values.\n",
      "    \n",
      "DifferenceVariance\n",
      "\n",
      "    **10. Difference Variance**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{difference variance} = \\displaystyle\\sum^{N_g-1}_{k=0}{(1-DA)^2p_{x-y}(k)}\n",
      "\n",
      "    Difference Variance is a measure of heterogeneity that places higher weights on\n",
      "    differing intensity level pairs that deviate more from the mean.\n",
      "    \n",
      "Idn\n",
      "\n",
      "    **21. Inverse Difference Normalized (IDN)**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{IDN} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}\n",
      "      { \\frac{p(i,j)}{1+\\left(\\frac{|i-j|}{N_g}\\right)} }\n",
      "\n",
      "    IDN (inverse difference normalized) is another measure of the local\n",
      "    homogeneity of an image. Unlike Homogeneity1, IDN normalizes the difference\n",
      "    between the neighboring intensity values by dividing over the total number\n",
      "    of discrete intensity values.\n",
      "    \n",
      "Idm\n",
      "\n",
      "    **18. Inverse Difference Moment (IDM)**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{IDM} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{ \\frac{p(i,j)}{1+|i-j|^2} }\n",
      "\n",
      "    IDM (inverse difference moment)  is a measure of the local\n",
      "    homogeneity of an image. IDM weights are the inverse of the Contrast\n",
      "    weights (decreasing exponentially from the diagonal i=j in the GLCM).\n",
      "    \n",
      "Correlation\n",
      "\n",
      "    **7. Correlation**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{correlation} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_g}_{j=1}{p(i,j)ij-\\mu_x(i)\\mu_y(j)}}{\\sigma_x(i)\\sigma_y(j)}\n",
      "\n",
      "    Correlation is a value between 0 (uncorrelated) and 1 (perfectly correlated) showing the\n",
      "    linear dependency of gray level values to their respective voxels in the GLCM.\n",
      "\n",
      "    .. note::\n",
      "\n",
      "      When there is only 1 discreet gray value in the ROI (flat region), :math:`\\sigma_x` and :math:`\\sigma_y` will be\n",
      "      0. In this case, an arbitrary value of 1 is returned instead. This is assessed on a per-angle basis.\n",
      "    \n",
      "Autocorrelation\n",
      "\n",
      "    **1. Autocorrelation**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{autocorrelation} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{p(i,j)ij}\n",
      "\n",
      "    Autocorrelation is a measure of the magnitude of the\n",
      "    fineness and coarseness of texture.\n",
      "    \n",
      "SumEntropy\n",
      "\n",
      "    **25. Sum Entropy**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{sum entropy} = \\displaystyle\\sum^{2N_g}_{k=2}{p_{x+y}(k)\\log_2\\big(p_{x+y}(k)+\\epsilon\\big)}\n",
      "\n",
      "    Sum Entropy is a sum of neighborhood intensity value differences.\n",
      "    \n",
      "AverageIntensity\n",
      "\n",
      "    **2. Joint Average**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\mu_x = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{p(i,j)i}\n",
      "\n",
      "    Returns the mean gray level intensity of the :math:`i` distribution.\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "      As this formula represents the average of the distribution of :math:`i`, it is independent from the\n",
      "      distribution of :math:`j`. Therefore, only use this formula if the GLCM is symmetrical, where\n",
      "      :math:`p_x(i) = p_y(j) \\text{, where } i = j`.\n",
      "    \n",
      "Energy\n",
      "\n",
      "    **12. Joint Energy**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{energy} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{\\big(p(i,j)\\big)^2}\n",
      "\n",
      "    Energy is a measure of homogeneous patterns\n",
      "    in the image. A greater Energy implies that there are more instances\n",
      "    of intensity value pairs in the image that neighbor each other at\n",
      "    higher frequencies.\n",
      "\n",
      "    .. note::\n",
      "      Defined by IBSI as Angular Second Moment.\n",
      "    \n",
      "SumSquares\n",
      "\n",
      "    **27. Sum of Squares**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{sum squares} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{(i-\\mu_x)^2p(i,j)}\n",
      "\n",
      "    Sum of Squares or Variance is a measure in the distribution of neigboring intensity level pairs\n",
      "    about the mean intensity level in the GLCM.\n",
      "\n",
      "    .. warning::\n",
      "\n",
      "      This formula represents the variance of the distribution of :math:`i` and is independent from the distribution\n",
      "      of :math:`j`. Therefore, only use this formula if the GLCM is symmetrical, where\n",
      "      :math:`p_x(i) = p_y(j) \\text{, where } i = j`\n",
      "\n",
      "    .. note::\n",
      "      Defined by IBSI as Joint Variance\n",
      "    \n",
      "ClusterProminence\n",
      "\n",
      "    **3. Cluster Prominence**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{cluster prominence} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}\n",
      "      {\\big( i+j-\\mu_x(i)-\\mu_y(j)\\big)^4p(i,j)}\n",
      "\n",
      "    Cluster Prominence is a measure of the skewness and asymmetry of the GLCM. A higher values implies more asymmetry\n",
      "    about the mean while a lower value indicates a peak near the mean value and less variation about the mean.\n",
      "    \n",
      "Entropy\n",
      "\n",
      "    **13. Joint Entropy**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{entropy} = -\\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}\n",
      "      {p(i,j)\\log_2\\big(p(i,j)+\\epsilon\\big)}\n",
      "\n",
      "    Entropy is a measure of the randomness/variability in neighborhood intensity values.\n",
      "\n",
      "    .. note::\n",
      "      Defined by IBSI as Joint entropy\n",
      "    \n",
      "Imc2\n",
      "\n",
      "    **17. Informal Measure of Correlation (IMC) 2**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{IMC 2} = \\sqrt{1-e^{-2(HXY2-HXY)}}\n",
      "\n",
      "    .. note::\n",
      "\n",
      "      In the case where HXY = HXY2, an arbitrary value of 0 is returned to prevent returning complex numbers. This is\n",
      "      done on a per-angle basis.\n",
      "    \n",
      "Imc1\n",
      "\n",
      "    **16. Informal Measure of Correlation (IMC) 1**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{IMC 1} = \\frac{HXY-HXY1}{\\max\\{HX,HY\\}}\n",
      "\n",
      "    .. note::\n",
      "\n",
      "      In the case where both HX and HY are 0 (as is the case in a flat region), an arbitrary value of 0 is returned to\n",
      "      prevent a division by 0. This is done on a per-angle basis\n",
      "    \n",
      "DifferenceAverage\n",
      "\n",
      "    **8. Difference Average**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{difference average} = \\displaystyle\\sum^{N_g-1}_{k=0}{kp_{x-y}(k)}\n",
      "\n",
      "    Difference Average measures the relationship between occurrences of pairs\n",
      "    with similar intensity values and occurrences of pairs with differing intensity\n",
      "    values.\n",
      "    \n",
      "Id\n",
      "\n",
      "    **20. Inverse Difference (ID)**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{ID} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}{ \\frac{p(i,j)}{1+|i-j|} }\n",
      "\n",
      "    ID (inverse difference) is another measure of the local homogeneity of an image.\n",
      "    With more uniform gray levels, the denominator will remain low, resulting in a higher overall value.\n",
      "    \n",
      "ClusterTendency\n",
      "\n",
      "    **5. Cluster Tendency**\n",
      "\n",
      "    .. math::\n",
      "\n",
      "      \\textit{cluster tendency} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_g}_{j=1}\n",
      "      {\\big(i+j-\\mu_x(i)-\\mu_y(j)\\big)^2p(i,j)}\n",
      "\n",
      "    Cluster Tendency is a measure of groupings of voxels with similar gray-level values.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following GLCM features: ')\n",
    "for f in glcmFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(getattr(glcmFeatures, 'get%sFeatureValue' % f).__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating GLCM features...\n",
      "done\n",
      "Calculated GLCM features: \n",
      "   SumVariance : 108.731393255\n",
      "   Homogeneity1 : 0.28722572383\n",
      "   Homogeneity2 : 0.200222556405\n",
      "   ClusterShade : 19.6050834273\n",
      "   MaximumProbability : 0.00735239226629\n",
      "   Idmn : 0.961402169623\n",
      "   Contrast : 47.4921251144\n",
      "   DifferenceEntropy : 3.74406097807\n",
      "   InverseVariance : 0.198818841971\n",
      "   Dissimilarity : 5.28446878987\n",
      "   SumAverage : 33.1076154489\n",
      "   DifferenceVariance : 16.6556370503\n",
      "   Idn : 0.87260521574\n",
      "   Idm : 0.200222556405\n",
      "   Correlation : 0.39175220067\n",
      "   Autocorrelation : 289.543699402\n",
      "   SumEntropy : 5.35424132149\n",
      "   AverageIntensity : 16.5538077244\n",
      "   Energy : 0.00289314924299\n",
      "   SumSquares : 39.0558795922\n",
      "   ClusterProminence : 27995.9375919\n",
      "   Entropy : 8.79969627025\n",
      "   Imc2 : 0.694224902067\n",
      "   Imc1 : -0.0943893880874\n",
      "   DifferenceAverage : 5.28446878987\n",
      "   Id : 0.28722572383\n",
      "   ClusterTendency : 108.731393255\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating GLCM features...',)\n",
    "glcmFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated GLCM features: ')\n",
    "for (key, val) in six.iteritems(glcmFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate GLRLM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glrlmFeatures = glrlm.RadiomicsGLRLM(croppedImage, croppedMask, **settings)\n",
    "\n",
    "# Set the features to be calculated\n",
    "# glrlmFeatures.enableFeatureByName('ShortRunEmphasis', True)\n",
    "glrlmFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following GLRLM features: \n",
      "ShortRunLowGrayLevelEmphasis\n",
      "\n",
      "    **13. Short Run Low Gray Level Emphasis (SRLGLE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{SRLGLE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)}{i^2j^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    SRLGLE measures the joint distribution of shorter run lengths with lower gray-level values.\n",
      "    \n",
      "GrayLevelVariance\n",
      "\n",
      "    **8. Gray Level Variance (GLV)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{GLV} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)(i - \\mu)^2}\n",
      "\n",
      "    Here, :math:`\\mu = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)i}`\n",
      "\n",
      "    GLV measures the variance in gray level intensity for the runs.\n",
      "    \n",
      "LowGrayLevelRunEmphasis\n",
      "\n",
      "    **11. Low Gray Level Run Emphasis (LGLRE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{LGLRE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)}{i^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    LGLRE measures the distribution of low gray-level values, with a higher value indicating a greater concentration of\n",
      "    low gray-level values in the image.\n",
      "    \n",
      "GrayLevelNonUniformityNormalized\n",
      "\n",
      "    **4. Gray Level Non-Uniformity Normalized (GLNN)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{GLNN} = \\frac{\\sum^{N_g}_{i=1}\\left(\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}\\right)^2}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}^2}\n",
      "\n",
      "    GLNN measures the similarity of gray-level intensity values in the image, where a lower GLNN value correlates with a\n",
      "    greater similarity in intensity values. This is the normalized version of the GLN formula.\n",
      "    \n",
      "RunVariance\n",
      "\n",
      "    **9. Run Variance (RV)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{RV} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)(j - \\mu)^2}\n",
      "\n",
      "    Here, :math:`\\mu = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{p(i,j|\\theta)j}`\n",
      "\n",
      "    RV is a measure of the variance in runs for the run lengths.\n",
      "    \n",
      "GrayLevelNonUniformity\n",
      "\n",
      "    **3. Gray Level Non-Uniformity (GLN)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{GLN} = \\frac{\\sum^{N_g}_{i=1}\\left(\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}\\right)^2}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    GLN measures the similarity of gray-level intensity values in the image, where a lower GLN value correlates with a\n",
      "    greater similarity in intensity values.\n",
      "    \n",
      "LongRunEmphasis\n",
      "\n",
      "    **2. Long Run Emphasis (LRE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{LRE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)j^2}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    LRE is a measure of the distribution of long run lengths, with a greater value indicative of longer run lengths and\n",
      "    more coarse structural textures.\n",
      "    \n",
      "ShortRunHighGrayLevelEmphasis\n",
      "\n",
      "    **14. Short Run High Gray Level Emphasis (SRHGLE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{SRHGLE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)i^2}{j^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    SRHGLE measures the joint distribution of shorter run lengths with higher gray-level values.\n",
      "    \n",
      "RunLengthNonUniformity\n",
      "\n",
      "    **5. Run Length Non-Uniformity (RLN)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{RLN} = \\frac{\\sum^{N_r}_{j=1}\\left(\\sum^{N_g}_{i=1}{\\textbf{P}(i,j|\\theta)}\\right)^2}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    RLN measures the similarity of run lengths throughout the image, with a lower value indicating more homogeneity\n",
      "    among run lengths in the image.\n",
      "    \n",
      "ShortRunEmphasis\n",
      "\n",
      "    **1. Short Run Emphasis (SRE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{SRE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)}{j^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    SRE is a measure of the distribution of short run lengths, with a greater value indicative of shorter run lengths\n",
      "    and more fine textural textures.\n",
      "    \n",
      "LongRunHighGrayLevelEmphasis\n",
      "\n",
      "    **16. Long Run High Gray Level Emphasis (LRHGLE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{LRHGLRE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)i^2j^2}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    LRHGLRE measures the joint distribution of long run lengths with higher gray-level values.\n",
      "    \n",
      "RunPercentage\n",
      "\n",
      "    **7. Run Percentage (RP)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{RP} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)}{N_p}}\n",
      "\n",
      "    RP measures the coarseness of the texture by taking the ratio of number of runs and number of voxels in the ROI.\n",
      "\n",
      "    Values are in range :math:`\\frac{1}{N_p} \\leq RP \\leq 1`, with higher values indicating a larger portion of the ROI\n",
      "    consists of short runs (indicates a more fine texture).\n",
      "\n",
      "    .. note::\n",
      "      Note that when weighting is applied and matrices are merged before calculation, :math:`N_p` is multiplied by\n",
      "      :math:`n` number of matrices merged to ensure correct normalization (as each voxel is considered :math:`n` times)\n",
      "    \n",
      "LongRunLowGrayLevelEmphasis\n",
      "\n",
      "    **15. Long Run Low Gray Level Emphasis (LRLGLE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{LRLGLRE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\frac{\\textbf{P}(i,j|\\theta)j^2}{i^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    LRLGLRE measures the joint distribution of long run lengths with lower gray-level values.\n",
      "    \n",
      "RunEntropy\n",
      "\n",
      "    **10. Run Entropy (RE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{RE} = -\\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_r}_{j=1}\n",
      "      {p(i,j|\\theta)\\log_{2}(p(i,j|\\theta)+\\epsilon)}\n",
      "\n",
      "    Here, :math:`\\epsilon` is an arbitrarily small positive number (:math:`\\approx 2.2\\times10^{-16}`).\n",
      "\n",
      "    RE measures the uncertainty/randomness in the distribution of run lengths and gray levels. A higher value indicates\n",
      "    more heterogeneity in the texture patterns.\n",
      "    \n",
      "HighGrayLevelRunEmphasis\n",
      "\n",
      "    **12. High Gray Level Run Emphasis (HGLRE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{HGLRE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)i^2}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    HGLRE measures the distribution of the higher gray-level values, with a higher value indicating a greater\n",
      "    concentration of high gray-level values in the image.\n",
      "    \n",
      "RunLengthNonUniformityNormalized\n",
      "\n",
      "    **6. Run Length Non-Uniformity Normalized (RLNN)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{RLNN} = \\frac{\\sum^{N_r}_{j=1}\\left(\\sum^{N_g}_{i=1}{\\textbf{P}(i,j|\\theta)}\\right)^2}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_r}_{j=1}{\\textbf{P}(i,j|\\theta)}}\n",
      "\n",
      "    RLNN measures the similarity of run lengths throughout the image, with a lower value indicating more homogeneity\n",
      "    among run lengths in the image. This is the normalized version of the RLN formula.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following GLRLM features: ')\n",
    "for f in glrlmFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(getattr(glrlmFeatures, 'get%sFeatureValue' % f).__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating GLRLM features...\n",
      "done\n",
      "Calculated GLRLM features: \n",
      "   ShortRunLowGrayLevelEmphasis : 0.00822976624416\n",
      "   GrayLevelVariance : 39.118151022\n",
      "   LowGrayLevelRunEmphasis : 0.00860039789166\n",
      "   GrayLevelNonUniformityNormalized : 0.0451412381498\n",
      "   RunVariance : 0.0847945778959\n",
      "   GrayLevelNonUniformity : 175.635192315\n",
      "   LongRunEmphasis : 1.22684403826\n",
      "   ShortRunHighGrayLevelEmphasis : 268.974179841\n",
      "   RunLengthNonUniformity : 3500.04323157\n",
      "   ShortRunEmphasis : 0.955939173141\n",
      "   LongRunHighGrayLevelEmphasis : 341.286579098\n",
      "   RunPercentage : 0.940406463249\n",
      "   LongRunLowGrayLevelEmphasis : 0.0106011704787\n",
      "   RunEntropy : 4.91503800316\n",
      "   HighGrayLevelRunEmphasis : 281.066493909\n",
      "   RunLengthNonUniformityNormalized : 0.895049465948\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating GLRLM features...',)\n",
    "glrlmFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated GLRLM features: ')\n",
    "for (key, val) in six.iteritems(glrlmFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate GLSZM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glszmFeatures = glszm.RadiomicsGLSZM(croppedImage, croppedMask, **settings)\n",
    "\n",
    "# Set the features to be calculated\n",
    "# glszmFeatures.enableFeatureByName('LargeAreaEmphasis', True)\n",
    "glszmFeatures.enableAllFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will calculate the following GLSZM features: \n",
      "GrayLevelVariance\n",
      "\n",
      "    **8. Gray Level Variance (GLV)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{GLV} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_s}_{j=1}{p(i,j)(i - \\mu)^2}\n",
      "\n",
      "    Here, :math:`\\mu = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_s}_{j=1}{p(i,j)i}`\n",
      "\n",
      "    GLV measures the variance in gray level intensities for the zones.\n",
      "    \n",
      "ZoneVariance\n",
      "\n",
      "    **9. Zone Variance (ZV)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{ZV} = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_s}_{j=1}{p(i,j)(j - \\mu)^2}\n",
      "\n",
      "    Here, :math:`\\mu = \\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_s}_{j=1}{p(i,j)j}`\n",
      "\n",
      "    ZV measures the variance in zone size volumes for the zones.\n",
      "    \n",
      "GrayLevelNonUniformityNormalized\n",
      "\n",
      "    **4. Gray Level Non-Uniformity Normalized (GLNN)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{GLNN} = \\frac{\\sum^{N_g}_{i=1}\\left(\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}\\right)^2}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_d}_{j=1}{\\textbf{P}(i,j)}^2}\n",
      "\n",
      "    GLNN measures the variability of gray-level intensity values in the image, with a lower value indicating a greater\n",
      "    similarity in intensity values. This is the normalized version of the GLN formula.\n",
      "    \n",
      "SizeZoneNonUniformityNormalized\n",
      "\n",
      "    **6. Size-Zone Non-Uniformity Normalized (SZNN)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{SZNN} = \\frac{\\sum^{N_s}_{j=1}\\left(\\sum^{N_g}_{i=1}{\\textbf{P}(i,j)}\\right)^2}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_d}_{j=1}{\\textbf{P}(i,j)}^2}\n",
      "\n",
      "    SZNN measures the variability of size zone volumes throughout the image, with a lower value indicating more\n",
      "    homogeneity among zone size volumes in the image. This is the normalized version of the SZN formula.\n",
      "    \n",
      "SizeZoneNonUniformity\n",
      "\n",
      "    **5. Size-Zone Non-Uniformity (SZN)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{SZN} = \\frac{\\sum^{N_s}_{j=1}\\left(\\sum^{N_g}_{i=1}{\\textbf{P}(i,j)}\\right)^2}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    SZN measures the variability of size zone volumes in the image, with a lower value indicating more homogeneity in\n",
      "    size zone volumes.\n",
      "    \n",
      "GrayLevelNonUniformity\n",
      "\n",
      "    **3. Gray Level Non-Uniformity (GLN)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{GLN} = \\frac{\\sum^{N_g}_{i=1}\\left(\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}\\right)^2}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    GLN measures the variability of gray-level intensity values in the image, with a lower value indicating more\n",
      "    homogeneity in intensity values.\n",
      "    \n",
      "LargeAreaEmphasis\n",
      "\n",
      "    **2. Large Area Emphasis (LAE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{LAE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)j^2}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    LAE is a measure of the distribution of large area size zones, with a greater value indicative of more larger size\n",
      "    zones and more coarse textures.\n",
      "    \n",
      "SmallAreaHighGrayLevelEmphasis\n",
      "\n",
      "    **14. Small Area High Gray Level Emphasis (SAHGLE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{SAHGLE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\frac{\\textbf{P}(i,j)i^2}{j^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    SAHGLE measures the proportion in the image of the joint distribution of smaller size zones with higher gray-level\n",
      "    values.\n",
      "    \n",
      "ZonePercentage\n",
      "\n",
      "    **7. Zone Percentage (ZP)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{ZP} = \\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\frac{\\textbf{P}(i,j)}{N_p}}\n",
      "\n",
      "    ZP measures the coarseness of the texture by taking the ratio of number of zones and number of voxels in the ROI.\n",
      "\n",
      "    Values are in range :math:`\\frac{1}{N_p} \\leq ZP \\leq 1`, with higher values indicating a larger portion of the ROI\n",
      "    consists of small zones (indicates a more fine texture).\n",
      "    \n",
      "LargeAreaLowGrayLevelEmphasis\n",
      "\n",
      "    **15. Large Area Low Gray Level Emphasis (LALGLE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{LALGLE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\frac{\\textbf{P}(i,j)j^2}{i^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    LALGLE measures the proportion in the image of the joint distribution of larger size zones with lower gray-level\n",
      "    values.\n",
      "    \n",
      "LargeAreaHighGrayLevelEmphasis\n",
      "\n",
      "    **16. Large Area High Gray Level Emphasis (LAHGLE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{LAHGLE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)i^2j^2}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    LAHGLE measures the proportion in the image of the joint distribution of larger size zones with higher gray-level\n",
      "    values.\n",
      "    \n",
      "HighGrayLevelZoneEmphasis\n",
      "\n",
      "    **12. High Gray Level Zone Emphasis (HGLZE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{HGLZE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)i^2}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    HGLZE measures the distribution of the higher gray-level values, with a higher value indicating a greater proportion\n",
      "    of higher gray-level values and size zones in the image.\n",
      "    \n",
      "SmallAreaEmphasis\n",
      "\n",
      "    **1. Small Area Emphasis (SAE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{SAE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\frac{\\textbf{P}(i,j)}{j^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    SAE is a measure of the distribution of small size zones, with a greater value indicative of more smaller size zones\n",
      "    and more fine textures.\n",
      "    \n",
      "LowGrayLevelZoneEmphasis\n",
      "\n",
      "    **11. Low Gray Level Zone Emphasis (LGLZE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{LGLZE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\frac{\\textbf{P}(i,j)}{i^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    LGLZE measures the distribution of lower gray-level size zones, with a higher value indicating a greater proportion\n",
      "    of lower gray-level values and size zones in the image.\n",
      "    \n",
      "ZoneEntropy\n",
      "\n",
      "    **10. Zone Entropy (ZE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{ZE} = -\\displaystyle\\sum^{N_g}_{i=1}\\displaystyle\\sum^{N_s}_{j=1}{p(i,j)\\log_{2}(p(i,j)+\\epsilon)}\n",
      "\n",
      "    Here, :math:`\\epsilon` is an arbitrarily small positive number (:math:`\\approx 2.2\\times10^{-16}`).\n",
      "\n",
      "    ZE measures the uncertainty/randomness in the distribution of zone sizes and gray levels. A higher value indicates\n",
      "    more heterogeneneity in the texture patterns.\n",
      "    \n",
      "SmallAreaLowGrayLevelEmphasis\n",
      "\n",
      "    **13. Small Area Low Gray Level Emphasis (SALGLE)**\n",
      "\n",
      "    .. math::\n",
      "      \\textit{SALGLE} = \\frac{\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\frac{\\textbf{P}(i,j)}{i^2j^2}}}\n",
      "      {\\sum^{N_g}_{i=1}\\sum^{N_s}_{j=1}{\\textbf{P}(i,j)}}\n",
      "\n",
      "    SALGLE measures the proportion in the image of the joint distribution of smaller size zones with lower gray-level\n",
      "    values.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Print out the docstrings of the enabled features\n",
    "print('Will calculate the following GLSZM features: ')\n",
    "for f in glszmFeatures.enabledFeatures.keys():\n",
    "  print(f)\n",
    "  print(getattr(glszmFeatures, 'get%sFeatureValue' % f).__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating GLSZM features...\n",
      "done\n",
      "Calculated GLSZM features: \n",
      "   GrayLevelVariance : 40.6031399239\n",
      "   SmallAreaHighGrayLevelEmphasis : 193.438051926\n",
      "   GrayLevelNonUniformityNormalized : 0.0440573079013\n",
      "   SizeZoneNonUniformityNormalized : 0.399784380451\n",
      "   SizeZoneNonUniformity : 747.596791444\n",
      "   GrayLevelNonUniformity : 82.3871657754\n",
      "   LargeAreaEmphasis : 13.6155080214\n",
      "   ZoneVariance : 8.72123909749\n",
      "   ZonePercentage : 0.4520183708\n",
      "   LargeAreaLowGrayLevelEmphasis : 0.127238415533\n",
      "   LargeAreaHighGrayLevelEmphasis : 3514.76149733\n",
      "   HighGrayLevelZoneEmphasis : 288.623529412\n",
      "   SmallAreaEmphasis : 0.656447899959\n",
      "   LowGrayLevelZoneEmphasis : 0.00910094202771\n",
      "   ZoneEntropy : 6.5082149862\n",
      "   SmallAreaLowGrayLevelEmphasis : 0.0064169820551\n"
     ]
    }
   ],
   "source": [
    "# Calculate the features and print(out result)\n",
    "print('Calculating GLSZM features...',)\n",
    "glszmFeatures.calculateFeatures()\n",
    "print('done')\n",
    "\n",
    "print('Calculated GLSZM features: ')\n",
    "for (key, val) in six.iteritems(glszmFeatures.featureValues):\n",
    "  print('  ', key, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Features using Laplacian of Gaussian Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating features on filtered images is very similar to calculating features on the original image. All filters in PyRadiomics have the same input and output signature, and there is even one for applying no filter. This enables to loop over a list of requested filters and apply them in the same piece of code. It is applied like this in the execute function in feature extractor. The input for the filters is the image, with additional keywords. If no additional keywords are supplied, the filter uses default values where applicable. It returns a [generator object](https://docs.python.org/2/reference/simple_stmts.html?#yield), allowing to define the generators to be applied before the filters functions are actually called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Firstorder on LoG filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logFeatures = {}\n",
    "sigmaValues = [1.0, 3.0, 5.0]\n",
    "for logImage, imageTypename, inputSettings in imageoperations.getLoGImage(image, sigma=sigmaValues):\n",
    "  logImage, croppedMask = imageoperations.cropToTumorMask(logImage, mask, bb)\n",
    "  logFirstorderFeatures = firstorder.RadiomicsFirstOrder(logImage, croppedMask, **inputSettings)\n",
    "  logFirstorderFeatures.enableAllFeatures()\n",
    "  logFirstorderFeatures.calculateFeatures()\n",
    "  logFeatures[imageTypename] = logFirstorderFeatures.featureValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   log-sigma-3-0-mm-3D_InterquartileRange : 103.158138275\n",
      "   log-sigma-3-0-mm-3D_Skewness : -0.498386343995\n",
      "   log-sigma-3-0-mm-3D_Uniformity : 0.0906478492348\n",
      "   log-sigma-3-0-mm-3D_MeanAbsoluteDeviation : 64.3312024633\n",
      "   log-sigma-3-0-mm-3D_Energy : 56119386.4932\n",
      "   log-sigma-3-0-mm-3D_RobustMeanAbsoluteDeviation : 43.3779243984\n",
      "   log-sigma-3-0-mm-3D_Median : -73.3129653931\n",
      "   log-sigma-3-0-mm-3D_TotalEnergy : 222641609.012\n",
      "   log-sigma-3-0-mm-3D_Maximum : 114.296691895\n",
      "   log-sigma-3-0-mm-3D_RootMeanSquared : 116.469898461\n",
      "   log-sigma-3-0-mm-3D_90Percentile : 13.9173410416\n",
      "   log-sigma-3-0-mm-3D_Minimum : -354.335235596\n",
      "   log-sigma-3-0-mm-3D_Entropy : 3.72121444058\n",
      "   log-sigma-3-0-mm-3D_StandardDeviation : 81.9760118492\n",
      "   log-sigma-3-0-mm-3D_Range : 468.63192749\n",
      "   log-sigma-3-0-mm-3D_Variance : 6720.06651871\n",
      "   log-sigma-3-0-mm-3D_10Percentile : -197.017340088\n",
      "   log-sigma-3-0-mm-3D_Kurtosis : 3.18336583197\n",
      "   log-sigma-3-0-mm-3D_Mean : -82.7355469484\n",
      "   log-sigma-1-0-mm-3D_InterquartileRange : 81.8767185211\n",
      "   log-sigma-1-0-mm-3D_Skewness : -0.220905251704\n",
      "   log-sigma-1-0-mm-3D_Uniformity : 0.114235313372\n",
      "   log-sigma-1-0-mm-3D_MeanAbsoluteDeviation : 49.6646616511\n",
      "   log-sigma-1-0-mm-3D_Energy : 18272859.744\n",
      "   log-sigma-1-0-mm-3D_RobustMeanAbsoluteDeviation : 34.3094515237\n",
      "   log-sigma-1-0-mm-3D_Median : -18.9197921753\n",
      "   log-sigma-1-0-mm-3D_TotalEnergy : 72493645.2247\n",
      "   log-sigma-1-0-mm-3D_Maximum : 164.726760864\n",
      "   log-sigma-1-0-mm-3D_RootMeanSquared : 66.460024941\n",
      "   log-sigma-1-0-mm-3D_90Percentile : 54.7903442383\n",
      "   log-sigma-1-0-mm-3D_Minimum : -255.259628296\n",
      "   log-sigma-1-0-mm-3D_Entropy : 3.37004955078\n",
      "   log-sigma-1-0-mm-3D_StandardDeviation : 62.6969503974\n",
      "   log-sigma-1-0-mm-3D_Range : 419.98638916\n",
      "   log-sigma-1-0-mm-3D_Variance : 3930.90758913\n",
      "   log-sigma-1-0-mm-3D_10Percentile : -104.93405304\n",
      "   log-sigma-1-0-mm-3D_Kurtosis : 3.07182438072\n",
      "   log-sigma-1-0-mm-3D_Mean : -22.0460274432\n",
      "   log-sigma-5-0-mm-3D_InterquartileRange : 106.342716217\n",
      "   log-sigma-5-0-mm-3D_Skewness : -0.30549686903\n",
      "   log-sigma-5-0-mm-3D_Uniformity : 0.0902675928609\n",
      "   log-sigma-5-0-mm-3D_MeanAbsoluteDeviation : 63.4364264458\n",
      "   log-sigma-5-0-mm-3D_Energy : 72664939.7252\n",
      "   log-sigma-5-0-mm-3D_RobustMeanAbsoluteDeviation : 43.2562957783\n",
      "   log-sigma-5-0-mm-3D_Median : -99.1174468994\n",
      "   log-sigma-5-0-mm-3D_TotalEnergy : 288282536.752\n",
      "   log-sigma-5-0-mm-3D_Maximum : 117.414512634\n",
      "   log-sigma-5-0-mm-3D_RootMeanSquared : 132.531678523\n",
      "   log-sigma-5-0-mm-3D_90Percentile : -10.6977561951\n",
      "   log-sigma-5-0-mm-3D_Minimum : -347.345001221\n",
      "   log-sigma-5-0-mm-3D_Entropy : 3.71336391413\n",
      "   log-sigma-5-0-mm-3D_StandardDeviation : 80.5220089107\n",
      "   log-sigma-5-0-mm-3D_Range : 464.759513855\n",
      "   log-sigma-5-0-mm-3D_Variance : 6483.79391901\n",
      "   log-sigma-5-0-mm-3D_10Percentile : -211.974316406\n",
      "   log-sigma-5-0-mm-3D_Kurtosis : 3.11489160873\n",
      "   log-sigma-5-0-mm-3D_Mean : -105.265625411\n"
     ]
    }
   ],
   "source": [
    "# Show result\n",
    "for sigma, features in six.iteritems(logFeatures):\n",
    "  for (key, val) in six.iteritems(features):\n",
    "    laplacianFeatureName = '%s_%s' % (str(sigma), key)\n",
    "    print('  ', laplacianFeatureName, ':', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Features using Wavelet filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Firstorder on filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated firstorder features with  wavelet-LHL\n",
      "Calculated firstorder features with  wavelet-LHH\n",
      "Calculated firstorder features with  wavelet-HLL\n",
      "Calculated firstorder features with  wavelet-LLH\n",
      "Calculated firstorder features with  wavelet-HLH\n",
      "Calculated firstorder features with  wavelet-HHH\n",
      "Calculated firstorder features with  wavelet-HHL\n",
      "Calculated firstorder features with  wavelet-LLL\n"
     ]
    }
   ],
   "source": [
    "waveletFeatures = {}\n",
    "for decompositionImage, decompositionName, inputSettings in imageoperations.getWaveletImage(image):\n",
    "  decompositionImage, croppedMask = imageoperations.cropToTumorMask(decompositionImage, mask, bb)\n",
    "  waveletFirstOrderFeaturs = firstorder.RadiomicsFirstOrder(decompositionImage, croppedMask, **inputSettings)\n",
    "  waveletFirstOrderFeaturs.enableAllFeatures()\n",
    "  waveletFirstOrderFeaturs.calculateFeatures()\n",
    "\n",
    "  print('Calculated firstorder features with ', decompositionName)\n",
    "  waveletFeatures[decompositionName] = waveletFirstOrderFeaturs.featureValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   wavelet-LLL_InterquartileRange : 550.594267427\n",
      "   wavelet-LLL_Skewness : 0.228846426465\n",
      "   wavelet-LLL_Uniformity : 0.0199077767278\n",
      "   wavelet-LLL_MeanAbsoluteDeviation : 293.143995944\n",
      "   wavelet-LLL_Energy : 21547005906.1\n",
      "   wavelet-LLL_RobustMeanAbsoluteDeviation : 220.739697172\n",
      "   wavelet-LLL_Median : 2244.88673609\n",
      "   wavelet-LLL_TotalEnergy : 85483116692.8\n",
      "   wavelet-LLL_Maximum : 3180.63918677\n",
      "   wavelet-LLL_RootMeanSquared : 2282.18425551\n",
      "   wavelet-LLL_90Percentile : 2739.69052111\n",
      "   wavelet-LLL_Minimum : 1468.07724103\n",
      "   wavelet-LLL_Entropy : 5.78300489052\n",
      "   wavelet-LLL_StandardDeviation : 350.172190209\n",
      "   wavelet-LLL_Range : 1712.56194574\n",
      "   wavelet-LLL_Variance : 122620.562796\n",
      "   wavelet-LLL_10Percentile : 1812.68473489\n",
      "   wavelet-LLL_Kurtosis : 2.27365643067\n",
      "   wavelet-LLL_Mean : 2255.1595095\n",
      "   wavelet-HHH_InterquartileRange : 20.3192746422\n",
      "   wavelet-HHH_Skewness : -0.0688112737237\n",
      "   wavelet-HHH_Uniformity : 0.382919979814\n",
      "   wavelet-HHH_MeanAbsoluteDeviation : 13.0759756862\n",
      "   wavelet-HHH_Energy : 1241014.78701\n",
      "   wavelet-HHH_RobustMeanAbsoluteDeviation : 8.53027450692\n",
      "   wavelet-HHH_Median : 0.109117292789\n",
      "   wavelet-HHH_TotalEnergy : 4923459.54321\n",
      "   wavelet-HHH_Maximum : 76.4099650187\n",
      "   wavelet-HHH_RootMeanSquared : 17.319913459\n",
      "   wavelet-HHH_90Percentile : 20.9238433344\n",
      "   wavelet-HHH_Minimum : -74.7556986689\n",
      "   wavelet-HHH_Entropy : 1.62781167475\n",
      "   wavelet-HHH_StandardDeviation : 17.3191286736\n",
      "   wavelet-HHH_Range : 151.165663688\n",
      "   wavelet-HHH_Variance : 299.952218013\n",
      "   wavelet-HHH_10Percentile : -21.0383130256\n",
      "   wavelet-HHH_Kurtosis : 4.32455549814\n",
      "   wavelet-HHH_Mean : 0.164876359429\n",
      "   wavelet-HLL_InterquartileRange : 53.6721220044\n",
      "   wavelet-HLL_Skewness : -0.514166044802\n",
      "   wavelet-HLL_Uniformity : 0.163587425574\n",
      "   wavelet-HLL_MeanAbsoluteDeviation : 35.7539421526\n",
      "   wavelet-HLL_Energy : 9738068.52047\n",
      "   wavelet-HLL_RobustMeanAbsoluteDeviation : 22.7497539081\n",
      "   wavelet-HLL_Median : -2.81720035764\n",
      "   wavelet-HLL_TotalEnergy : 38633694.6918\n",
      "   wavelet-HLL_Maximum : 186.246123128\n",
      "   wavelet-HLL_RootMeanSquared : 48.516968019\n",
      "   wavelet-HLL_90Percentile : 50.858801791\n",
      "   wavelet-HLL_Minimum : -291.543962261\n",
      "   wavelet-HLL_Entropy : 2.95573220857\n",
      "   wavelet-HLL_StandardDeviation : 48.2505612367\n",
      "   wavelet-HLL_Range : 477.790085389\n",
      "   wavelet-HLL_Variance : 2328.11665966\n",
      "   wavelet-HLL_10Percentile : -62.825323625\n",
      "   wavelet-HLL_Kurtosis : 5.09932613055\n",
      "   wavelet-HLL_Mean : -5.07735424173\n",
      "   wavelet-HHL_InterquartileRange : 22.3805938159\n",
      "   wavelet-HHL_Skewness : 0.121890250304\n",
      "   wavelet-HHL_Uniformity : 0.358701481744\n",
      "   wavelet-HHL_MeanAbsoluteDeviation : 14.4086961805\n",
      "   wavelet-HHL_Energy : 1537525.52337\n",
      "   wavelet-HHL_RobustMeanAbsoluteDeviation : 9.30098915932\n",
      "   wavelet-HHL_Median : 0.0829386441652\n",
      "   wavelet-HHL_TotalEnergy : 6099802.18624\n",
      "   wavelet-HHL_Maximum : 96.9275598214\n",
      "   wavelet-HHL_RootMeanSquared : 19.2782854506\n",
      "   wavelet-HHL_90Percentile : 23.0361222477\n",
      "   wavelet-HHL_Minimum : -100.72323161\n",
      "   wavelet-HHL_Entropy : 1.75422760497\n",
      "   wavelet-HHL_StandardDeviation : 19.2752766031\n",
      "   wavelet-HHL_Range : 197.650791431\n",
      "   wavelet-HHL_Variance : 371.536288126\n",
      "   wavelet-HHL_10Percentile : -22.0062020433\n",
      "   wavelet-HHL_Kurtosis : 4.71302154772\n",
      "   wavelet-HHL_Mean : 0.340590352112\n",
      "   wavelet-LLH_InterquartileRange : 352.67245821\n",
      "   wavelet-LLH_Skewness : -0.525773815287\n",
      "   wavelet-LLH_Uniformity : 0.0304399667913\n",
      "   wavelet-LLH_MeanAbsoluteDeviation : 205.422769392\n",
      "   wavelet-LLH_Energy : 263973676.505\n",
      "   wavelet-LLH_RobustMeanAbsoluteDeviation : 146.79059076\n",
      "   wavelet-LLH_Median : 62.7368130339\n",
      "   wavelet-LLH_TotalEnergy : 1047258848.44\n",
      "   wavelet-LLH_Maximum : 733.850508276\n",
      "   wavelet-LLH_RootMeanSquared : 252.602445134\n",
      "   wavelet-LLH_90Percentile : 297.911610403\n",
      "   wavelet-LLH_Minimum : -783.008892644\n",
      "   wavelet-LLH_Entropy : 5.27888924024\n",
      "   wavelet-LLH_StandardDeviation : 252.406755064\n",
      "   wavelet-LLH_Range : 1516.85940092\n",
      "   wavelet-LLH_Variance : 63709.1700017\n",
      "   wavelet-LLH_10Percentile : -370.145218742\n",
      "   wavelet-LLH_Kurtosis : 2.69674899921\n",
      "   wavelet-LLH_Mean : 9.94109078503\n",
      "   wavelet-HLH_InterquartileRange : 44.1166822627\n",
      "   wavelet-HLH_Skewness : -0.109634215846\n",
      "   wavelet-HLH_Uniformity : 0.192969183516\n",
      "   wavelet-HLH_MeanAbsoluteDeviation : 30.6419982661\n",
      "   wavelet-HLH_Energy : 7500010.61679\n",
      "   wavelet-HLH_RobustMeanAbsoluteDeviation : 18.8328798407\n",
      "   wavelet-HLH_Median : -0.788893809524\n",
      "   wavelet-HLH_TotalEnergy : 29754680.7917\n",
      "   wavelet-HLH_Maximum : 195.252851267\n",
      "   wavelet-HLH_RootMeanSquared : 42.5782863744\n",
      "   wavelet-HLH_90Percentile : 48.8399961041\n",
      "   wavelet-HLH_Minimum : -254.072696334\n",
      "   wavelet-HLH_Entropy : 2.75501833527\n",
      "   wavelet-HLH_StandardDeviation : 42.5781351255\n",
      "   wavelet-HLH_Range : 449.325547601\n",
      "   wavelet-HLH_Variance : 1812.89759077\n",
      "   wavelet-HLH_10Percentile : -48.7973652241\n",
      "   wavelet-HLH_Kurtosis : 5.96264006105\n",
      "   wavelet-HLH_Mean : -0.113489262994\n",
      "   wavelet-LHL_InterquartileRange : 71.4997770702\n",
      "   wavelet-LHL_Skewness : -0.369538595422\n",
      "   wavelet-LHL_Uniformity : 0.121366697967\n",
      "   wavelet-LHL_MeanAbsoluteDeviation : 48.9628822529\n",
      "   wavelet-LHL_Energy : 18447257.2048\n",
      "   wavelet-LHL_RobustMeanAbsoluteDeviation : 30.6452121553\n",
      "   wavelet-LHL_Median : -4.09721168383\n",
      "   wavelet-LHL_TotalEnergy : 73185529.6822\n",
      "   wavelet-LHL_Maximum : 286.571219987\n",
      "   wavelet-LHL_RootMeanSquared : 66.7764213865\n",
      "   wavelet-LHL_90Percentile : 71.5796532291\n",
      "   wavelet-LHL_Minimum : -354.894733038\n",
      "   wavelet-LHL_Entropy : 3.40407739189\n",
      "   wavelet-LHL_StandardDeviation : 66.5740051389\n",
      "   wavelet-LHL_Range : 641.465953025\n",
      "   wavelet-LHL_Variance : 4432.09816024\n",
      "   wavelet-LHL_10Percentile : -85.6408963111\n",
      "   wavelet-LHL_Kurtosis : 4.82046635261\n",
      "   wavelet-LHL_Mean : -5.19541075848\n",
      "   wavelet-LHH_InterquartileRange : 61.7174514323\n",
      "   wavelet-LHH_Skewness : 0.197382131363\n",
      "   wavelet-LHH_Uniformity : 0.140809788318\n",
      "   wavelet-LHH_MeanAbsoluteDeviation : 41.6368845931\n",
      "   wavelet-LHH_Energy : 13202719.5692\n",
      "   wavelet-LHH_RobustMeanAbsoluteDeviation : 26.4723285429\n",
      "   wavelet-LHH_Median : -1.94009209997\n",
      "   wavelet-LHH_TotalEnergy : 52378953.3691\n",
      "   wavelet-LHH_Maximum : 279.350380756\n",
      "   wavelet-LHH_RootMeanSquared : 56.4922586614\n",
      "   wavelet-LHH_90Percentile : 63.2151706827\n",
      "   wavelet-LHH_Minimum : -324.703453682\n",
      "   wavelet-LHH_Entropy : 3.17918664471\n",
      "   wavelet-LHH_StandardDeviation : 56.4734198287\n",
      "   wavelet-LHH_Range : 604.053834439\n",
      "   wavelet-LHH_Variance : 3189.24714715\n",
      "   wavelet-LHH_10Percentile : -69.1252699081\n",
      "   wavelet-LHH_Kurtosis : 5.10438678184\n",
      "   wavelet-LHH_Mean : -1.45881510799\n"
     ]
    }
   ],
   "source": [
    "# Show result\n",
    "for decompositionName, features in six.iteritems(waveletFeatures):\n",
    "  for (key, val) in six.iteritems(features):\n",
    "    waveletFeatureName = '%s_%s' % (str(decompositionName), key)\n",
    "    print('  ', waveletFeatureName, ':', val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
